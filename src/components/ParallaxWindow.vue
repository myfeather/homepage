<template>
    <span class="prose-img-container image-like">
        <canvas v-if="!prefersReducedMotion" class="image-like-content" ref="parallaxCanvas"></canvas>
        <img v-else class="image-like-content" :src="fallbackImageSrc" :alt="alt" />
        <div v-if="alt" class="prose-img-caption">
            <strong>Fig.</strong>
            <span class="caption-text">{{ alt }}</span>
        </div>
    </span>
</template>

<script setup lang="ts">
import { ref, onMounted, onBeforeUnmount, computed } from 'vue';

const props = withDefaults(defineProps<{
    albedo?: string,
    depth?: string,
    src?: string,
    alt?: string,
    offsetX?: number,
    offsetY?: number,
    sensitivityX?: number,
    sensitivityY?: number,
    viewHeight?: number
}>(), {
    albedo: "",
    depth: "",
    alt: "",
    offsetX: 0,
    offsetY: 0,
    sensitivityX: 0.004,
    sensitivityY: 0.004,
    viewHeight: 1
});

// Derive albedo and depth from src if provided
const derivedAlbedo = computed(() => {
    if (props.src) {
        const ext = props.src.match(/\.[^.]+$/)?.[0] || '';
        return props.src.replace(ext, `-albedo${ext}`);
    }
    return props.albedo;
});

const derivedDepth = computed(() => {
    if (props.src) {
        const ext = props.src.match(/\.[^.]+$/)?.[0] || '';
        return props.src.replace(ext, `-depth${ext}`);
    }
    return props.depth;
});

// Fallback image source (use albedo when reduced motion is enabled)
const fallbackImageSrc = computed(() => props.src || derivedAlbedo.value);

const parallaxCanvas = ref<HTMLCanvasElement | null>(null);
let renderFn: ((offsetX: number, offsetY: number) => void) | null = null;
const imageAspectRatio = ref<number | null>(null);
const prefersReducedMotion = ref(false);
let resizeObserver: ResizeObserver | null = null;
let resizeRaf = 0;
let lastCanvasSize = { width: 0, height: 0 };

// --- WebGL helper functions ---
function loadTexture(gl: WebGLRenderingContext, url: string): Promise<{ texture: WebGLTexture; width: number; height: number }> {
    return new Promise(resolve => {
        const image = new Image();
        image.onload = () => {
            const tex = gl.createTexture()!;
            gl.bindTexture(gl.TEXTURE_2D, tex);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image);
            resolve({ texture: tex, width: image.width, height: image.height });
        };
        image.src = url;
    });
}

function compileShader(gl: WebGLRenderingContext, type: number, source: string): WebGLShader | null {
    const shader = gl.createShader(type);
    if (!shader) return null;
    gl.shaderSource(shader, source);
    gl.compileShader(shader);
    if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
        console.error(gl.getShaderInfoLog(shader));
        return null;
    }
    return shader;
}

function setupGeometry(gl: WebGLRenderingContext, program: WebGLProgram) {
    const vertices = new Float32Array([-1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1]);
    const buffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
    gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);
    const posAttrib = gl.getAttribLocation(program, 'a_position');
    gl.enableVertexAttribArray(posAttrib);
    gl.vertexAttribPointer(posAttrib, 2, gl.FLOAT, false, 0, 0);
}

// --- Shader setup ---
async function setupShader(canvas: HTMLCanvasElement) {
    if (!canvas) return null;
    const gl = canvas.getContext('webgl');
    if (!gl) return null;

    // vertex shader
    const vertSrc = `
          attribute vec4 a_position;
          varying vec2 v_uv;
          void main() {
              gl_Position = a_position;
              v_uv = a_position.xy * 0.5 + 0.5;
          }
      `;
    const fragSrc = await fetch('/parallax.glsl')
        .then(r => r.text())
        .catch(() => 'precision mediump float; void main() { gl_FragColor = vec4(1,0,0,1); }');

    const vertShader = compileShader(gl, gl.VERTEX_SHADER, vertSrc);
    const fragShader = compileShader(gl, gl.FRAGMENT_SHADER, fragSrc);
    if (!vertShader || !fragShader) return null;

    const program = gl.createProgram()!;
    gl.attachShader(program, vertShader);
    gl.attachShader(program, fragShader);
    gl.linkProgram(program);
    gl.useProgram(program);

    setupGeometry(gl, program);

    const albedoResult = await loadTexture(gl, derivedAlbedo.value);
    const depthResult = await loadTexture(gl, derivedDepth.value);

    // Set aspect ratio from image dimensions
    imageAspectRatio.value = albedoResult.width / albedoResult.height;

    const uniforms = {
        uOffset: gl.getUniformLocation(program, 'u_offset'),
        uSampler: gl.getUniformLocation(program, 'u_texture'),
        uDepth: gl.getUniformLocation(program, 'u_depth'),
        uRes: gl.getUniformLocation(program, 'u_resolution'),
        uImageRes: gl.getUniformLocation(program, 'u_imageRes'),
        uSensitivity: gl.getUniformLocation(program, 'u_sensitivity'),
        uImageScale: gl.getUniformLocation(program, 'u_imageScale'),
        uImageTranslate: gl.getUniformLocation(program, 'u_imageTranslate'),
        uHorizontalScale: gl.getUniformLocation(program, 'u_horizontalScale'),
        uAlignmentOffset: gl.getUniformLocation(program, 'u_alignmentOffset'),
        uDepthCenter: gl.getUniformLocation(program, 'u_depthCenter'),
        uDepthPower: gl.getUniformLocation(program, 'u_depthPower'),
        uDepthCenter2: gl.getUniformLocation(program, 'u_depthCenter2'),
        uRotationPivot: gl.getUniformLocation(program, 'u_rotationPivot'),
        uViewHeight: gl.getUniformLocation(program, 'u_viewHeight'),
    };

    const render = (offsetX: number = 0, offsetY: number = 0) => {
        if (!canvas) return;
        const dpr = window.devicePixelRatio || 1;
        const displayWidth = Math.floor(canvas.clientWidth * dpr);
        const displayHeight = Math.floor(canvas.clientHeight * dpr);

        if (canvas.width !== displayWidth || canvas.height !== displayHeight) {
            canvas.width = displayWidth;
            canvas.height = displayHeight;
            gl.viewport(0, 0, canvas.width, canvas.height);
        }

        gl.clearColor(0, 0, 0, 0);
        gl.clear(gl.COLOR_BUFFER_BIT);

        // Combine base props offset with dynamic offset
        const totalOffsetX = props.offsetX + offsetX;
        const totalOffsetY = props.offsetY + offsetY;

        gl.uniform2f(uniforms.uOffset, totalOffsetX, totalOffsetY);
        gl.uniform2f(uniforms.uRes, canvas.width, canvas.height);
        gl.uniform2f(uniforms.uImageRes, albedoResult.width, albedoResult.height);
        gl.uniform2f(uniforms.uSensitivity, props.sensitivityX, props.sensitivityY);
        gl.uniform1f(uniforms.uViewHeight, props.viewHeight);

        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, albedoResult.texture);
        gl.uniform1i(uniforms.uSampler, 0);

        gl.activeTexture(gl.TEXTURE1);
        gl.bindTexture(gl.TEXTURE_2D, depthResult.texture);
        gl.uniform1i(uniforms.uDepth, 1);

        gl.drawArrays(gl.TRIANGLES, 0, 6);
    };

    return { render };
}

onMounted(async () => {
    // Check for prefers-reduced-motion preference
    const mediaQuery = window.matchMedia('(prefers-reduced-motion: reduce)');
    prefersReducedMotion.value = mediaQuery.matches;

    // Only setup WebGL if reduced motion is not preferred
    if (!prefersReducedMotion.value && parallaxCanvas.value) {
        const shader = await setupShader(parallaxCanvas.value);
        if (shader) {
            renderFn = shader.render;
            resizeObserver = new ResizeObserver(() => {
                if (!parallaxCanvas.value || !renderFn) return;
                if (resizeRaf) cancelAnimationFrame(resizeRaf);
                resizeRaf = requestAnimationFrame(() => {
                    resizeRaf = 0;
                    const width = parallaxCanvas.value!.clientWidth;
                    const height = parallaxCanvas.value!.clientHeight;
                    if (width === lastCanvasSize.width && height === lastCanvasSize.height) return;
                    lastCanvasSize = { width, height };
                    renderFn?.(props.offsetX, props.offsetY);
                });
            });
            resizeObserver.observe(parallaxCanvas.value);
        }
    } else {
        // Set aspect ratio from fallback image when reduced motion is enabled
        const img = new Image();
        img.onload = () => {
            imageAspectRatio.value = img.width / img.height;
        };
        img.src = fallbackImageSrc.value;
    }
});

onBeforeUnmount(() => {
    if (resizeRaf) cancelAnimationFrame(resizeRaf);
    resizeRaf = 0;
    resizeObserver?.disconnect();
    resizeObserver = null;
});

defineExpose({
    render: (offsetX: number = 0, offsetY: number = 0) => {
        if (renderFn) renderFn(offsetX, offsetY);
    },
    $el: parallaxCanvas
});
</script>

<style lang="scss" scoped>
canvas,
img {
    aspect-ratio: v-bind(imageAspectRatio);
}
</style>
